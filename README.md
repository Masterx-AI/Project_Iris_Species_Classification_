# <center>AI / ML Project - Iris Species Classification ðŸ¥€</center>
<p align="center"><img src="https://user-images.githubusercontent.com/54996245/141647531-227c963b-6e00-4b3a-bb5d-7ade49598eb5.jpg" width="1000"/></p>

### Description:
* The Iris Dataset consists of mutiple samples of Iris Flower.
* The Iris flower is categorized into 3 species namely - Setosa, Versicolor & Virginica.<br>
* These species vary in the dimensions of the sepals & petals.

### Objective:
- Import the Iris Dataset from sklearn library.
- Build classification models to predict the species.
- Compare the evaluation metrics of vaious classification algorithms.

### The Project is divided into the following steps:
1. Data Exploration
2. Exploratory Data Analysis
3. Data Preprocessing
4. Data Manipulation
5. Predictive Modeling
6. Project Outcomes & Conclusions
  
### Some Visuals of the Project:

1. Target Variable Distribution
<p align="left"><img src="https://user-images.githubusercontent.com/54996245/140614833-b4743269-e3e0-4cef-b3c4-cbc17529cad3.png" /></p>

2. Feature-set Distribution
![image](https://user-images.githubusercontent.com/54996245/140614979-eb4fedf4-ed65-4022-9c5e-e92003d481b0.png)
![image](https://user-images.githubusercontent.com/54996245/140614994-bececcc9-23d9-4428-a5b5-48cd028c18d4.png)

3. Relationship between the Feature-set
![image](https://user-images.githubusercontent.com/54996245/140615006-63a294ef-e66b-4819-94de-152d60d9e6f1.png)

4. Data Retention after preforming preprocessing step

![image](https://user-images.githubusercontent.com/54996245/140615012-ba0ea2a2-9b8c-4aa7-82c9-8ce2bca6c4ad.png)

5. ML Algorithm's Scores for the Iris Dataset
![image](https://user-images.githubusercontent.com/54996245/140615041-10ae0518-b801-41cd-a3fa-9ca186d6e82a.png)


### Here are some of the key outcomes of the project:
- The Dataset was quiet small totally just 150 samples & after preprocessing 3.3% of the datasamples were dropped. It was also balanced & didn't require any artificial techniques to balance it.
- Visualising the distribution of data & their relationships, helped us to get some insights on the class seperability.
- Feature selection or feature extracting as there were only 4 features, which all contributed towards the right prediction.
- Testing multiple algorithms with default hyperparamters gave us some understanding for various models performance on this specific dataset.
- While, Decision Tree Classifier algorithm gave the best overall scores for the current dataset, yet it wise to also consider simpler models as they are more generalisable.

